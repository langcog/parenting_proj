---
title: "Parenting observation lexical diversity"
author: "Emily"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
---

# Data preprocessing

Preliminaries.

```{r echo=FALSE}
knitr::opts_chunk$set(fig.width=8, fig.height=5, 
                      echo=TRUE, warning=FALSE, message=FALSE, cache = TRUE)
suppressPackageStartupMessages(c("dplyr","langcog","tidyr","ggplot2","lme4"))
library(psych)
library(langcog)
library(tidyverse)
library(ggthemes)
library(lme4)
library(lmerTest)

select <- dplyr::select # masked by MASS
theme_set(theme_few())
```

Read in participant data.

```{r}
data <- read.csv("lexdiv_data.csv", header =TRUE)
dem <- read.csv("parenting_proj_emilyhembacher_demo2016.csv", header =TRUE)
conditions <- read.csv("joint_attention/conditions.csv")
load("paq/paq_demo.RData")

#fix ids
data$SID <- stringr::str_trim(data$SID)
data$SID <- stringr::str_replace(data$SID, "_cut.txt", "")
data$SID <- stringr::str_replace(data$SID, "8283_", "")
data$SID <- stringr::str_replace(data$SID, "283_", "")
data$SID <- stringr::str_replace(data$SID, "_cut_save.txt", "")
data$SID <- stringr::str_replace(data$SID, "_cut_save", "")
data$SID <- stringr::str_replace(data$SID, "_cutsave.txt", "")
data$SID <- stringr::str_replace(data$SID, "parenting_obs_", "0")
data$SID <- stringr::str_replace(data$SID, "_cut_m4a.txt", "")

data$SID <- stringr::str_replace(data$SID, "05116_05", "050116_05")
data$SID <- stringr::str_replace(data$SID, "05116_2", "050116_02")
```

Make data frames. 

```{r}
d <- left_join(data, conditions)%>%
  left_join(dem)%>%
  transmute(sid=SID, 
            types = Type.count, 
            tokens = Token.count, 
            lexdiv = Lexical.diversity, 
            condition= Condition, 
            video = Video, 
            age = age,
            gender = gender,
            parent_ed = parent_ed)%>%
  left_join(ids)%>%
  filter(!is.na(condition))
```

#Plots

##Lexical Diversity
```{r}
ms_lex <- d %>%
  group_by(condition) %>%
  multi_boot_standard(col = "lexdiv") 

lex_means <- d%>%
  group_by(condition)%>%
  summarise(mean = mean(lexdiv))

lex_sds <- d%>%
  group_by(condition)%>%
  summarise(sd = sd(lexdiv))

ms_lex$condition <- factor(ms_lex$condition,
levels = c("con", "exp"),
labels = c("control", "video"))

ggplot(ms_lex, aes(x = condition, y = mean, fill = condition)) + 
  geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
             position = position_dodge(width = .9))+
  xlab("Condition") + 
  ylab("Lexical Diversity") +
  langcog::scale_colour_solarized()  +
  ggthemes::theme_few() + 
  theme(legend.title = element_text(size=18), 
        legend.text = element_text(size=16), 
        axis.text.x  = element_text(vjust=0.5, size=16),
        axis.title.x = element_text(size=18), 
        axis.text.y  = element_text(vjust=0.5, size=16),
        axis.title.y = element_text(size=18))
```

##Word Tokens
```{r}
ms_tok <- d %>%
  group_by(condition) %>%
  multi_boot_standard(col = "tokens") 

ms_tok$condition <- factor(ms_tok$condition,
levels = c("con", "exp"),
labels = c("control", "video"))

ggplot(ms_tok, aes(x = condition, y = mean, fill = condition)) + 
  geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
             position = position_dodge(width = .9))+
  xlab("Condition") + 
  ylab("Total Number of Word Tokens") +
  langcog::scale_colour_solarized()  +
  ggthemes::theme_few() + 
  theme(legend.title = element_text(size=18), 
        legend.text = element_text(size=16), 
        axis.text.x  = element_text(vjust=0.5, size=16),
        axis.title.x = element_text(size=18), 
        axis.text.y  = element_text(vjust=0.5, size=16),
        axis.title.y = element_text(size=18))
```

##Word Types
```{r}
ms_type <- d %>%
  group_by(condition) %>%
  multi_boot_standard(col = "types") 

ms_type$condition <- factor(ms_type$condition,
levels = c("con", "exp"),
labels = c("control", "video"))

ggplot(ms_tok, aes(x = condition, y = mean, fill = condition)) + 
  geom_bar(stat="identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
             position = position_dodge(width = .9))+
  xlab("Condition") + 
  ylab("Total Number of Word Types") +
  langcog::scale_colour_solarized()  +
  ggthemes::theme_few() + 
  theme(legend.title = element_text(size=18), 
        legend.text = element_text(size=16), 
        axis.text.x  = element_text(vjust=0.5, size=16),
        axis.title.x = element_text(size=18), 
        axis.text.y  = element_text(vjust=0.5, size=16),
        axis.title.y = element_text(size=18))
```

#Analyses

Prepare data.
```{r}
lmer_data <- d %>%
  filter(!is.na(AA), !is.na(EL), !is.na(RR))%>%
  mutate(condition = factor(condition), 
         lexdiv = as.numeric(lexdiv),
         EL = as.numeric(langcog::scale(EL, scale=FALSE)),
         AA = as.numeric(langcog::scale(AA, scale=FALSE)),
         RR = as.numeric(langcog::scale(RR, scale=FALSE)),
         age = as.numeric(langcog::scale(age, scale=FALSE)),
         gender = as.factor(gender),
         video = as.factor(video))
```

##Lexical diversity
Predicting lexical diversity based on experimental condition, PAQ, demographics. 
```{r}
maximal_mod <- lmer(lexdiv ~ condition  + age + gender + parent_ed +
                           (1| video), 
                         data = lmer_data)
summary(maximal_mod)

#get effect size

M1 <- lex_means$mean[1]
M2 <- lex_means$mean[2]
SD1 <- lex_sds$sd[1]
SD2 <- lex_sds$sd[2]

cohens_d <- (M2 - M1)/(sqrt(SD1^2 + SD2^2)/2)
```

##Word tokens
Predicting the number of word tokens based on experimental condition, PAQ, demographics.  
```{r}
maximal_mod <- lmer(tokens ~ condition *  EL  + condition * AA + condition * RR  + age + gender + parent_ed +
                           (1| video), 
                         data = lmer_data)
summary(maximal_mod)
```

##Word types
Predicting the number of word types based on experimental condition, PAQ, demographics.  
```{r}
maximal_mod <- lmer(types ~ condition *  EL  + condition * AA + condition * RR  + age + gender + parent_ed +
                           (1| video), 
                         data = lmer_data)
summary(maximal_mod)
```

#Conclusions

Both the number of tokens and types are higher in the experimental condition, while lexical diversity (type-token ratio) is higher in the control condition. Parents may be relatively more repetetive in the experimental condition since they are attempting to stick to a specific prescribed task, but they talk more overall! Demographics and PAQ do not interact with condition, but there is a marginal effect of RR score on lexical diversity (lower ld for higher RR scores), and marginal effects of parent education on word types and tokens (more types and tokens for higher parent ed).