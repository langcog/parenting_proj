---
title: "Measuring lay theories of parenting and child development"
bibliography: parenting_old.bib
csl: apa6.csl
document-params: "10pt, letterpaper"
nocite: | 
  @kumar2015
author-information: 
    \author{{\large \bf Emily Hembacher} \\ \texttt{ehembach@stanford.edu} \\ Department of Psychology \\ Stanford University \And {\large \bf Michael C. Frank} \\ \texttt{mcfrank@stanford.edu} \\ Department of Psychology \\ Stanford University}

abstract: 
    "Child development research suggests that parenting practices play an important role in shaping children’s outcomes. For example, children whose parents engage them in high-quality conversations and who are given opportunities for free play are at an advantage for learning and later academic outcomes. However, communicating the results of relevant scientific findings to parents remains a challenge. One possible moderator of uptake of parenting information is the implicit theories parents hold with regard to child development and parenting. As a first step in investigating this possibility, the present work establishes a new measure of parenting attitudes including three subscales corresponding to lay theories about rules and respect, affection and attachment, and early learning. We then examine whether subscale scores differentially predict uptake of a popular press article about children’s early learning. Scores on the early learning subscale, but not the rules and respect subscale, predicted generalization from the article, providing first evidence of the validity of this measure."

keywords:
    "Parenting attitudes; implicit theories"

output: 
  cogsci2016::cogsci_paper:
    keep_tex: true
---


```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width=3.5, fig.height=3, fig.crop = FALSE, 
fig.pos = "ht", fig.path='figs/',
echo=FALSE, warning=FALSE, cache=TRUE, 
message=FALSE, sanitize=TRUE)
```

```{r, libraries}
library(psych)
library(rjson)
library(psych)
library(nFactors)
library(lme4)
library(tidyr)
library(knitr)
library(ggplot2)
library(dplyr)
library(langcog)
library(directlabels)
library(stringr)
library(magrittr)
library(readr)
library(ggrepel)
library(xtable)

select <- dplyr::select # masked by MASS
```

Child development research is constantly generating information that can be brought to bear on best practices for parenting. For example, research on children’s learning has demonstrated that pedagogy can improve learning in some contexts and limit it in others, suggesting that allowing children to play freely and explore is critical for learning [@bonawitz2011;@buchsbaum2011]. Likewise, a great deal of research has demonstrated the importance of engaging young children in elaborative conversations for language development and future academic success [@hart1995;@hoff2003]. A fundamental challenge we face is how to communicate the results of such scientific inquiry to a diverse public in a way that maximizes uptake and improves people’s daily and long-term decision making. 

One critical parameter that may moderate parenting behavior is parents’ lay theories about child development and parenting. Lay theories reflect the core beliefs that people hold in different domains, which may or may not be explicitly articulated, but organize the processing of new information and decision-making [@dweck1988;@ong2015]. For example, people with an entity theory of personality tend to interpret people’s behaviors as stemming from fixed personality traits rather than situational factors such as needs, goals, or emotional states [@dweck1995]. 

There are two reasons to focus on parents’ lay theories. First, parents’ lay theories might be an important explanatory factor for many of the behaviors parents engage in with their child. For example, a parent who believes that building a strong emotional bond with their baby is one of the most important goals of parenting might have more physical contact with their child than a parent who does not hold this theory. Secondly, parents’ lay theories may moderate the uptake of new information about parenting. It is well-established that people more easily encode new information that is consistent with an existing schema or mental model they hold [@bransford1972]. In addition, previous research has found that interventions on public health beliefs are more successful when they take into account people’s existing belief structures in the domain (Kumar et al., 2015). 

There is some evidence supporting the notion that parents’ behaviors are mediated by implicit lay theories about child development, which vary by SES and across cultures. For example, cross-cultural studies have found profound differences in how parents interact with infants. @richman1992 found that mothers in the Gusii community of Kenya primarily engaged with their children to soothe them when upset, but did not often speak to them with the goal of engaging or stimulating them, as did Caucasian parents in the United States. The authors attribute this behavior to cultural conventions stemming from the belief that there is no purpose in speaking to infants, as they will not understand what is being said [@richman1992;@levine2004].

There are also important differences in how parents within western cultures interact with their children. Numerous studies have identified SES disparity in the amount that parents talk to their children, which in turn predicts children’s language and academic outcomes [@hoff2003;@huttenlocher2002]. In an effort to identify the source of this disparity, @rowe2008 discovered that parents’ knowledge of child development (as indexed by their scores on the Knowledge of Infant Development Inventory; KIDI) predicted their child-directed language, with more knowledgeable parents speaking to their children more even when controlling for the amount of speech directed at another adult. Although this study examined parents’ knowledge, and not their lay theories _per se_, it provides evidence that people’s domain knowledge has real consequences for their interactions with their children. 

\begin{table*}[t]
\centering
\begin{tabular}{p{1.25in}p{5.25in}}
  \hline
Subscale & Full item \\ 
  \hline
Rules and Respect & It is very important that children learn to respect adults, such as parents and teachers. \\ 
   & It is important for young children to learn to control their impulses (e.g., waiting when told to wait). \\ 
  & Children should be taught to be grateful to their parents. \\ 
  & Children should not be punished for breaking small rules.* \\ 
  & Parents should follow their children's lead rather than imposing structure in the form of rules.* \\ 
  & Young children should be allowed to make their own decisions, such as what to eat for dinner.* \\ 
  \hline
  Affection and Attachment & Parents need to provide safe and loving environments for their children. \\ 
   & Holding and cradling babies is important for forming strong bonds between parent and child. \\ 
   & Children should be given comfort and understanding when they are scared or unhappy. \\ 
   & Parents do not need to talk to their child about his or her emotions.* \\ 
   & Children become spoiled if they receive too much attention from parents.* \\ 
   & Too much affection can make a child weak.* \\ 
   \hline
  Early Learning & Children can learn about things like good and bad behavior from a very early age. \\ 
   & Young children can teach themselves things by exploring and playing. \\ 
   & Babies repetitive behaviors (e.g., banging a cup on the table) are a way for them to explore cause and effect. \\ 
   & It is not helpful for adults to explain the reasons for rules to young children because they won't understand.* \\ 
   & Children don't need to learn about numbers and math until they go to school.* \\ 
   & Reading books to children is not helpful if they have not yet learned to speak.* \\ 
   \hline
\end{tabular}
\caption{Parenting Attitudes Scale items. *Indicates reverse coded items.\label{tab:items}}
\end{table*}

There are many other examples of parenting beliefs on which parents differ. For example, there is a large body of research based on @baumrind1971’s framework that identifies parents as authoritative, authoritarian, or permissive, according to their levels of responsiveness and control in their interactions with their children. In sum, parents’ approaches to parenting appear to vary in predictable ways based on their knowledge and perceptions about children’s learning and development. 

Although these previous studies provide preliminary evidence that parents’ beliefs about parenting and child development affect their parenting behaviors, no previous research has attempted to identify the underlying _theories_ that might organize their behavior and decision-making. Previous research has generally relied on observation of parent-child interactions or self-report of specific activities and behaviors. To our knowledge there is not an existing measure of parents’ more general attitudes about parenting and child development, which might drive behavior and predict the uptake of interventions. 

To address this gap, the present work establishes a self-report scale that captures adults’ lay theories about child development and parenting. We generated a questionnaire measuring the degree to which parents endorse three potential lay theories: a “Rules and Respect” theory, an “Affection and Attachment” theory, and an “Early Learning” theory. As an initial test of the external validity of the questionnaire, we conducted an experiment to investigate whether parents’ scores on these subscales would differentially predict their uptake of parenting information presented via a popular press article about children’s early learning from free play (Gopnik, 2011). Higher scores on the Early Learning subscale predicted improved uptake in terms of both recall and generalization of information from the article about children's learning, but not a control article. Furthermore, the Rules and Respect subscale predicted improved uptake in terms of recall but not generalization of the presented information, suggesting that parents' implicit theories do affect how they process and use new information about child development, and that these differences may be detectable through self-report measures.

# Scale Construction

To establish a new measure of parenting attitudes, we followed a structured plan based on psychometric best practices [@clark1995;@furr2011;@simms2008]. We generated items corresponding to three hypothesized latent theories about parenting. The Early Learning theory corresponds to a view of children’s early learning that is consistent with contemporary child development research, and includes the idea that young children can teach themselves by exploring and playing. The Affection and Attachment theory captures the notion that close parent-child relationships are important for development, and includes the ideas that parents should talk to their children about their emotions and that children are not spoiled by too much affection. The Rules and Respect theory corresponds to the idea that parents’ primary role is to enforce rules and encourage behavior control. We generated hypothesized subscales and items based on a review of the literature on parenting attitudes, and conducted psychometric analyses on iterative samples of respondents collected on Amazon Mechanical Turk, both parents and non-parents (seven in total).

```{r}
files <- dir("../production-results/e7/")
d.raw <- data.frame()

for (f in files) {
  jf <- paste("../production-results/e7/",f,sep="")
  jd <- fromJSON(paste(readLines(jf), collapse=""))
  
  # clean up instruction trial
  sent <- jd$answers$data$sentence
  rating <- as.numeric(jd$answers$data$rating) 
  trial_type <- jd$answer$data$trial_type
  sent <- sent[trial_type != "2afc_instructions"]
  trial_type <- trial_type[trial_type != "2afc_instructions"]
  
  id <- data.frame(workerid = jd$WorkerId, 
                   sent = sent,
                   rating = rating,
                   children = jd$answers$data$children,
                   language = jd$answer$data$homelang,
                   ses = jd$answer$data$ladder,
                   gender = jd$answer$data$gender,
                   age = jd$answer$data$age,
                   education = jd$answer$data$education,
                   ethnicity = jd$answer$data$ethnicity,
                   childAgeYoung = jd$answer$data$childAgeYoung,
                   childAgeOld = jd$answer$data$childAgeOld
                   )
  d.raw <- bind_rows(d.raw, id)
}
```


```{r}
labels <- read.csv("../analysis/sent_forms_e7.csv")
labels$sent <- as.character(labels$sent)
```


```{r}
d.raw$sent <- as.character(d.raw$sent)
d.raw$sent <- str_replace_all(d.raw$sent, "'", "")
d.raw$sent <- str_replace_all(d.raw$sent, "’", "")
d.raw$sent <- str_replace_all(d.raw$sent, "“", "")
d.raw$sent <- str_replace_all(d.raw$sent, "”", "")
d.raw$sent <- str_replace_all(d.raw$sent, "‘", "")
d.raw$sent <- str_replace_all(d.raw$sent, "â", "")
```

```{r}
d <- left_join(d.raw, labels)
d$rating[d$reverse_code == 1] <- 6 - d$rating[d$reverse_code == 1]
```

```{r}
subinfo <- d %>% 
  group_by(workerid) %>%
  select(workerid, age, gender, children, ses, education, language, 
         ethnicity, childAgeYoung, childAgeOld) %>%
  dplyr::rename(youngestChildAge = childAgeYoung,
         oldestChildAge = childAgeOld) %>%
  distinct
```

```{r}
ss <- d %>%
  dplyr::group_by(workerid, category) %>%
  dplyr::summarise(rating = mean(rating))

ss <- left_join(ss, subinfo)
```


```{r}
ms <- ss %>% 
  filter(gender %in% c("Male","Female")) %>%
  group_by(gender, category) %>%
  multi_boot_standard(col = "rating") 

# ggplot(ms, aes(category, mean, fill=gender)) +
#   geom_bar(stat="identity", position = "dodge") + 
#   geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
#              position = position_dodge(width = .9)) + 
#   scale_fill_solarized()
# 
# kable(coef(summary(lmer(rating ~ category * gender + (1|workerid), 
#      data =   ss %>% filter(gender %in% c("Male","Female"))))), digits = 2)

```


```{r}
ms <- ss %>% 
  filter(!is.na(children), children != "") %>%
  mutate(parent = children != "0") %>%
  group_by(parent, category) %>%
  multi_boot_standard(col = "rating") 

# ggplot(ms, aes(category, mean, fill=parent)) +
#   geom_bar(stat="identity", position = "dodge") + 
#   geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
#              position = position_dodge(width = .9)) + 
#   scale_fill_solarized()
# 
# knitr::kable(coef(summary(lmer(rating ~ category * parent + (1|workerid), 
#      data = ss %>% 
#        filter(!is.na(children), children != "") %>%
#        mutate(parent = children != "0")))), digits = 2)

```

```{r}
wide.attitudes <- d %>% 
  filter(instrument == "attitudes") %>%
  select(workerid, short_sent, rating) %>% 
  spread(short_sent, rating)
```

```{r}
att.mat <- select(wide.attitudes, -workerid)

ev <- eigen(cor(x=att.mat)) # get eigenvalues

ap <- parallel(subject=nrow(att.mat), var=ncol(att.mat),
               rep=100,cent=.05)
nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)
# plotnScree(nS)
```

```{r loadings, fig.height=3, fig.width=7, fig.env='figure*', fig.align='center', fig.pos='', fig.cap='Factor loadings for subscale items. EL = Early Learning, AA = Affection and Attachment, RR = Rules and Respect. *Indicates reverse-coded items.'}

n.factors <- 3

af <- factanal(x=att.mat, factors = n.factors, scores = "regression")
loadings <- data.frame(af$loadings[,1:n.factors]) %>%
  mutate(item = rownames(af$loadings)) %>%
  gather(factor, loading, starts_with("Factor"))

labels$item <- labels$short_sent
loadings <- left_join(loadings, labels, by = "item")

loadings$Category <- factor(loadings$category, 
                            levels = c("early_learning","affection_attachment",
                                       "rules_respect"),
                            labels = c("EL", 
                                       "AA", 
                                       "RR"))
qplot(factor, item, fill=loading, geom="tile", data = loadings) + 
  scale_fill_continuous(low="#000000", high="#FFFFFF") + 
  facet_grid(Category ~ ., scales = "free_y")
```


## Item construction 

In an initial phase of scale construction, we generated 42 statements that described attitudes consistent with one of three potential implicit theories about parenting: Early Learning (12 items; e.g., “Children can learn about things like good and bad behavior from an early age”), Affection and Attachment (10 items; e.g., “It's important for a baby to have a strong bond with mom”), and Rules and Respect (20 items; e.g., “It is very important that children learn to respect adults, such as parents and teachers”). These statements were generated based on a literature review of parenting attitudes and behaviors. The Affection and Attachment and Rules and Respect subscales are related theoretically to the Authoritative and Authoritarian dimensions of @baumrind1971's parenting framework, as well as theories of attachment parenting [@jones2014], but aim to assess beliefs about parenting rather than overt behaviors. The Early Learning subscale aimed to assess the extent to which adults believe that it is important to help infants and toddlers learn through play and conversation. 

The initial 42-item scale was administered to 250 adults on Amazon's Mechanical Turk. Participants used a 7-point Likert scale to report the degree to which they agreed with each statement from 0 (Do not Agree) to 6 (Strongly Agree). Cronbach’s alphas for the three subscales were .86 (Early Learning), .81 (Affection and Attachment), and .74 (Rules and Respect). We then conducted Exploratory Factor Analysis (EFA) to assess the dimensionality of the scale. Based on a parallel analysis [@horn1965], we retained 5 factors in this initial model. We subsequently dropped any items that had factor loadings less than .40 on the relevant factor, as well as any items that had factor loadings greater than .40 onto another factor. Items were also dropped if analyses revealed that Cronbach’s alpha would be increased by dropping the item. We then dropped additional items with lower loadings until there were 6 items in each subscale. Some items were rephrased such that half of the items in each subscale were negatively worded to avoid response sets [@simms2008].


## Revised questionnaire norming


```{r}
a.scores <- af$scores %>%
  data.frame %>%
  mutate(workerid = as.character(wide.attitudes$workerid)) %>%
  left_join(subinfo)
```


```{r}

a.factor.names <- c("Affection and Early Learning","Rules and Respect", "Affection 2")

mf <- a.scores %>% 
  gather(factor, score, starts_with("Factor")) %>%
  filter(gender %in% c("Male","Female")) %>%
  mutate(factor.num = as.numeric(str_replace(factor,"Factor","")),
         factor.name = a.factor.names[factor.num]) %>%
  group_by(gender, factor.name) %>%
  multi_boot_standard(col = "score") 

# ggplot(mf, aes(factor.name, mean, fill=gender)) +
#   geom_bar(stat="identity", position = "dodge") + 
#   geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
#              position = position_dodge(width = .9)) + 
#   scale_fill_solarized()

```


The revised questionnaire was administered to a final group of 250 adults on Amazon's Mechanical Turk. Table \ref{tab:items} gives the full list of items^[The most recent version of the questionnaire is available at https://github.com/langcog/parenting_proj]. For this sample, Cronbach’s alphas were .76 (Early Learning), .75 (Affection and Attachment), and .69 (Rules and Respect). Because analysis of the previous sample identified 5 factors instead of the hypothesized 3, we again conducted EFA. This time, the parallel analysis identified 3 factors as predicted. We next examined the loadings of individual items onto the three factors (Figure \ref{fig:loadings}). Items loaded onto the three factors roughly consistent with our a priori subscales, although some items from the Affection and Attachment subscale loaded onto both the Affection and Attachment and Early Learning factors. 

Given the loadings of Early Learning and Affection and Attachment items onto a single factor, it is possible that participants’ responses on these items were driven by a more general hands-on attitude towards parenting. Interestingly, when we conducted an exploratory analysis of factor loadings by gender, we found that female gender loaded highly positively onto the Affection and Attachment factor that did not include Early Learning items (.44), while the opposite was true for male gender (-.20). Thus, it is possible that these items reflect a theory related to Affection and Attachment that is separable from the hands-on approach and differentiated by gender.

\begin{table*}[!h]
\centering
\begin{tabular}{p{1.25in}p{5.25in}}
  \hline
Uptake category \\ 
  \hline
Control recall 
& According to Article 2, what do the groups known for having many words for smells have in common? \\ 
  & A) They train their children to be able to tell the difference between smells.\\ 
  & B) They are hunter-gatherers.*\\ 
  & C) They have unusually good hearing and vision.\\ 
\hline
Target recall
  & According to Article 1, children were more likely to find new and better ways to make a toy work when the experimenter:\\ 
  & A) Pretended to be clueless about how the toy worked when playing with it.*\\ 
  & B) Pretended to be an expert about the toy when playing with it.\\ 
  & C) Pretended not to care about the toy.\\ 
  \hline
  Target generalization 
  & Based on Article 1, preschool directors should plan to have:\\ 
  & A) More structured time in which children are taught lessons and skills.\\ 
  & B) More time spent memorizing things that will be helpful later, such as the ABCs.\\
  & C) More time for children to play outside and with toys.*\\
  \hline
\end{tabular}
\caption{Examples of uptake questions. *Marks correct answer. \label{tab:uptake}} 
\end{table*}

As one test of the external validity of the subscales, we fit linear mixed-effects models predicting subscale scores based on gender and parenthood status (i.e., whether or not the participant reported having children) with participants as random effects. The model including gender revealed that females had higher scores on Early Learning, ($\beta = 0.41$, _SE_ = .19, _p_ = .03), and marginally higher scores for Affection and Attachment ($\beta = 0.34$, _SE_ = .23, _p_ = .14), whereas gender had no effect on Rules and Respect scores. The model including parenthood status revealed that parents had higher scores on the Affection and Attachment subscale compared to non-parents, ($\beta = 0.35$, _SE_ = .13, _p_ = .006), whereas parenthood status had no effect on Early Learning or Rules and Respect scores. These differences provide some intuitive support for the notion that subscale scores tap meaningful constructs that vary across groups. 

```{r items, results="asis"}

# items <- read.csv("../analysis/scale_items.csv") %>% 
#   gather(subscale, item, starts_with("R"),starts_with("A"),starts_with("E")  )

# colnames(items) <- c("Rules and Respect", "Affection and Attachment", "Early Learning")

#scale_table <- xtable(items, caption = "Parenting Attitudes Scale")

#print(scale_table, type = "latex", comment = FALSE, include.rownames = FALSE,
#      table.placement = "t", format.args = list(big.mark = ","))
```

```{r}
files <- dir("../production-results/uptake_e2/")
d.raw <- data.frame()

for (f in files) {
  jf <- paste("../production-results/uptake_e2/",f,sep="")
  jd <- fromJSON(paste(readLines(jf), collapse=""))
  
  # clean up different tasks
  trial_type <- jd$answer$data$trial_type
  
  #parenting questionnaire 
  sent <- jd$answers$data$sentence[trial_type != "uptake"]
  rating <- as.numeric(jd$answers$data$rating[trial_type != "uptake"]) 
  
  #uptake experiment
  control_recall_1 = as.character(jd$answers$data$answer[1])
  control_recall_2 = as.character(jd$answers$data$answer[2])
  control_recall_3 = as.character(jd$answers$data$answer[3])
  control_recall_4 = as.character(jd$answers$data$answer[4])
  control_recall_5 = as.character(jd$answers$data$answer[5])
  target_generalize_1 = as.character(jd$answers$data$answer[6])
  target_generalize_2 = as.character(jd$answers$data$answer[7])
  target_generalize_3 = as.character(jd$answers$data$answer[8])
  target_generalize_4 = as.character(jd$answers$data$answer[9])
  target_generalize_5 = as.character(jd$answers$data$answer[10])
  target_recall_1 = as.character(jd$answers$data$answer[11])
  target_recall_2 = as.character(jd$answers$data$answer[12])
  target_recall_3 = as.character(jd$answers$data$answer[13])
  target_recall_4 = as.character(jd$answers$data$answer[14])
  target_recall_5 = as.character(jd$answers$data$answer[15])
  reading_time_target = jd$answers$data$target_rt[1]
  reading_time_control = jd$answers$data$control_rt[1]
  time_questionnaire = jd$answers$data$questionnaire_rt[1]
  
  
  #demographics
  race <- as.character(jd$answers$data$race[1])
  
  id <- data.frame(workerid = jd$WorkerId, 
                   sent = sent,
                   rating = rating,
                   enjoy_target = jd$answers$data$enjoy_target,
                   enjoy_control = jd$answers$data$enjoy_control,
                   reading_ease_target = jd$answers$data$reading_ease_target,
                   reading_ease_control = jd$answers$data$reading_ease_control,
                   target_recall_1 = target_recall_1,
                   target_recall_2 = target_recall_2,
                   target_recall_3 = target_recall_3,
                   target_recall_4 = target_recall_4,
                   target_recall_5 = target_recall_5,
                   target_generalize_1 = target_generalize_1,
                   target_generalize_2 = target_generalize_2,
                   target_generalize_3 = target_generalize_3,
                   target_generalize_4 = target_generalize_4,
                   target_generalize_5 = target_generalize_5,
                   control_recall_1 = control_recall_1,
                   control_recall_2 = control_recall_2,
                   control_recall_3 = control_recall_3,
                   control_recall_4 = control_recall_4,
                   control_recall_5 = control_recall_5,
                   children = jd$answers$data$children,
                   language = jd$answers$data$homelang,
                   ses = jd$answers$data$ladder,
                   gender = jd$answers$data$gender,
                   age = jd$answers$data$age,
                   education = jd$answers$data$education,
                   ethnicity = jd$answers$data$ethnicity,
                   childAgeYoung = jd$answers$data$childAgeYoung,
                   childAgeOld = jd$answers$data$childAgeOld,
                   race = race,
                   reading_time_target = reading_time_target,
                   reading_time_control = reading_time_control,
                   time_questionnaire = time_questionnaire)
  d.raw <- bind_rows(d.raw, id)
}

```



```{r}
labels <- read.csv("../analysis/sent_forms_e7.csv")
labels$sent <- as.character(labels$sent)

answers <- read.csv("../analysis/uptake_key.csv")
answers$tar_gen <-as.character(answers$tar_gen)
answers$tar_rec <-as.character(answers$tar_rec)
answers$con_rec <-as.character(answers$con_rec)
```


```{r}
d.raw$sent <- as.character(d.raw$sent)
d.raw$sent <- str_replace_all(d.raw$sent, "'", "")
d.raw$sent <- str_replace_all(d.raw$sent, "’", "")
d.raw$sent <- str_replace_all(d.raw$sent, "“", "")
d.raw$sent <- str_replace_all(d.raw$sent, "”", "")
d.raw$sent <- str_replace_all(d.raw$sent, "‘", "")
d.raw$sent <- str_replace_all(d.raw$sent, "â", "")
```


```{r}
d <- left_join(d.raw, labels)
d$rating[d$reverse_code == 1] <- 6 - d$rating[d$reverse_code == 1]

d$target_generalize_1[d$target_generalize_1 != answers$tar_gen[1]] <- 0
d$target_generalize_1[d$target_generalize_1 == answers$tar_gen[1]] <- 1
d$target_generalize_2[d$target_generalize_2 != answers$tar_gen[2]] <- 0
d$target_generalize_2[d$target_generalize_2 == answers$tar_gen[2]] <- 1
d$target_generalize_3[d$target_generalize_3 != answers$tar_gen[3]] <- 0
d$target_generalize_3[d$target_generalize_3 == answers$tar_gen[3]] <- 1
d$target_generalize_4[d$target_generalize_4 != answers$tar_gen[4]] <- 0
d$target_generalize_4[d$target_generalize_4 == answers$tar_gen[4]] <- 1
d$target_generalize_5[d$target_generalize_5 != answers$tar_gen[5]] <- 0
d$target_generalize_5[d$target_generalize_5 == answers$tar_gen[5]] <- 1

d$target_recall_1[d$target_recall_1 != answers$tar_rec[1]] <- 0
d$target_recall_1[d$target_recall_1 == answers$tar_rec[1]] <- 1
d$target_recall_2[d$target_recall_2 != answers$tar_rec[2]] <- 0
d$target_recall_2[d$target_recall_2 == answers$tar_rec[2]] <- 1
d$target_recall_3[d$target_recall_3 != answers$tar_rec[3]] <- 0
d$target_recall_3[d$target_recall_3 == answers$tar_rec[3]] <- 1
d$target_recall_4[d$target_recall_4 != answers$tar_rec[4]] <- 0
d$target_recall_4[d$target_recall_4 == answers$tar_rec[4]] <- 1
d$target_recall_5[d$target_recall_5 != answers$tar_rec[5]] <- 0
d$target_recall_5[d$target_recall_5 == answers$tar_rec[5]] <- 1

d$control_recall_1[d$control_recall_1 != answers$con_rec[1]] <- 0
d$control_recall_1[d$control_recall_1 == answers$con_rec[1]] <- 1
d$control_recall_2[d$control_recall_2 != answers$con_rec[2]] <- 0
d$control_recall_2[d$control_recall_2 == answers$con_rec[2]] <- 1
d$control_recall_3[d$control_recall_3 != answers$con_rec[3]] <- 0
d$control_recall_3[d$control_recall_3 == answers$con_rec[3]] <- 1
d$control_recall_4[d$control_recall_4 != answers$con_rec[4]] <- 0
d$control_recall_4[d$control_recall_4 == answers$con_rec[4]] <- 1
d$control_recall_5[d$control_recall_5 != answers$con_rec[5]] <- 0
d$control_recall_5[d$control_recall_5 == answers$con_rec[5]] <- 1
```


```{r}
subinfo <- d %>%
  group_by(workerid) %>%
  select(-short_sent, -category, -instrument, -reverse_code) %>%
  distinct 

questions <- subinfo %>%
  select(workerid, starts_with("target"), starts_with("control")) %>%
  tidyr::gather(question, correct, starts_with("target"), starts_with("control")) %>%
  tidyr::separate(question, c("passage","trial_type","q_num"), sep = "_") %>%
  group_by(workerid, passage, trial_type) %>%
  summarise(correct = mean(as.numeric(correct))) %>%
  tidyr::unite(trialtype, passage, trial_type) %>%
  tidyr::spread(trialtype, correct)

subinfo <- subinfo %>%
  select(-starts_with("target"), -starts_with("control")) %>%
  left_join(questions) %>%
  select(-sent, -rating)
```

# Experiment 

We next conducted an experiment to test whether scores on the three subscales would predict people’s uptake of new information, as an initial test of the external validity of the scales. For this purpose, we had participants read two popular press articles: an article arguing that free play is beneficial to children’s learning (Gopnik, 2011), and a control article about the language of smell [@yong2015]. We operationalized uptake as accurate recall and generalization of the central message of the target article, and recall of the control article. We predicted that if people’s subscale scores reflect coherent lay theories, they should differentially moderate uptake of the two articles. Specifically, we predicted that scores on the Early Learning subscale would be positively related to recall and generalization of the target article, but not recall of the control article. We predicted that scores on the Rules and Respect subscale would not predict uptake of either article. We excluded scores on the Affection and Attachment subscale from our analyses, since they are not orthogonal to scores on the Early Learning subscale. A sample analysis plan was pregistered at 
osf.io/6umza.

## Methods

### Participants

Participants were `r length(unique(d.raw$workerid))` adults recruited from Amazon Mechanical Turk. Of these participants, `r sum(subinfo$children == "0")` reported having children, `r sum(subinfo$children != "0" & subinfo$children != "")` reported having no children, and `r sum(subinfo$children == "")` did not respond. 

### Procedure

Participants first completed the 18-item parenting questionnaire described above. They were then instructed to read two popular press articles at their own pace. They first read a target article about children's early learning ("Why Preschool Shouldn't Be Like School," Alison Gopnik, Slate, 2011), and then read a control article about the language of smell ("Why Do Most Languages Have So Few Words For Smells?", Ed Yong, The Atlantic, 2015). After reading both articles, they first answered five 3-alternative forced-choice recall questions about the control article, and then answered five 3AFC generalization and five 3AFC recall questions about the target article. The recall questions assessed participants' memory for specific details of the text, and the generalization questions assessed participants' ability to generalize from the meaning of the text to new situations (Table \ref{tab:uptake}). The alternative choices for recall and generalization questions were designed to reflect reasonable options that were nonetheless inconsistent with the articles.


## Results and discussion

```{r}
# 
# ms <- d %>%
#   group_by(category, instrument, short_sent, reverse_code) %>%
#   multi_boot_standard(col = "rating") %>%
#   arrange(instrument, category, desc(mean)) 
# 
# ms$short_sent_ord <- factor(ms$short_sent, 
#                              levels = ms$short_sent)

ds <- d
ds$srating <- ave(ds$rating, ds$category, FUN=scale)

ss <- ds %>%
  group_by(workerid, category) %>%
  summarize(srating = mean(srating)) %>%
  tidyr::spread(category, srating) %>% 
  left_join(subinfo) %>%
  tidyr::gather(trial_type, correct, control_recall, target_recall, target_generalize)

ss.long <- ss %>%
  tidyr::gather(subscale, srating, early_learning,rules_respect)

exclude <- subinfo$workerid[subinfo$reading_time_target < 30 | 
                              subinfo$reading_time_control < 30]
# length(exclude)
```

As a planned exclusion criterion, we excluded `r length(exclude)` participants who spent less than 30 seconds reading one or both of the articles, based on the assumption that they had not had time to read the whole article. Mean accuracy for the remaining sample was `r round(mean(subinfo$control_recall[!subinfo$workerid %in% exclude]),2)` (_SD_ = `r round(sd(subinfo$control_recall[!subinfo$workerid %in% exclude]),2)`) for control recall, `r round(mean(subinfo$target_recall[!subinfo$workerid %in% exclude]),2)` (_SD_ = `r round(sd(subinfo$target_recall[!subinfo$workerid %in% exclude]),2)`) for target recall, and `r round(mean(subinfo$target_generalize[!subinfo$workerid %in% exclude]),2)` (_SD_ = `r round(sd(subinfo$target_generalize[!subinfo$workerid %in% exclude]),2)`) for target generalization. 

```{r relation, fig.height=3, fig.width=7, fig.env='figure*', fig.align='center', fig.pos='t', fig.cap="Relationship between subscale scores and uptake. Dots show individual participants. Lines show linear models and 95\\% CIs. Points are jittered to avoid overplotting."}

ss.long$Subscale <- factor(ss.long$subscale, 
                           levels = c("early_learning","rules_respect"), 
                           labels = c("Early Learning","Rules and Respect"))
ss.long$Trial_type <- factor(ss.long$trial_type, 
                           levels = c("control_recall","target_recall",
                                      "target_generalize"), 
                           labels = c("Control recall","Target recall",
                                      "Target generalization"))

ggplot(filter(ss.long, !workerid %in% exclude), 
       aes(x = srating, y = correct, col = Subscale)) +
  geom_jitter() + 
  geom_smooth(method="lm") + 
  facet_wrap(~Trial_type) + 
  theme_bw() + 
  ylab("Proportion correct") + 
  ylim(c(0,1)) + 
  xlab("Subscale score (standardized)") +
  scale_colour_solarized() + 
  theme(legend.key = element_blank(),
        legend.background = element_rect(fill = "transparent"),
        legend.margin = unit(0, "mm"),
        legend.position = "bottom",
        legend.direction = "horizontal")
```

Figure \ref{fig:relation} shows proportion correct on each of the three trial types, plotted by standardized subscale scores. Regression lines show the relationship between subscale scores and proportion correct. Qualitatively, there was not strong evidence of a relationship between Rules and Respect scores and performance (though target recall showed some trend). In contrast, we observed a stronger relationship between performance and Early Learning scores, especially for target generalization trials. 

```{r}
subscales <- ds %>%
  group_by(workerid, category) %>%
  summarize(srating = mean(srating)) %>%
  tidyr::spread(category, srating) 

ratings <- d %>% 
  select(workerid, starts_with("target"), starts_with("control")) %>%
  tidyr::gather(question, correct, starts_with("target"), starts_with("control")) %>%
  tidyr::separate(question, c("passage","trial_type","q_num"), sep = "_") %>%
  mutate(correct = as.numeric(correct), 
         q_num = as.numeric(q_num) + 
           as.numeric(factor(passage)) * 10 + 
           as.numeric(factor(trial_type)) * 100)

d.reg <- left_join(ratings, subscales) %>%
  tidyr::unite(question_type, passage, trial_type)

lm <- glmer(correct ~ question_type * rules_respect + 
                question_type * early_learning + 
                (1|workerid) + 
                (1|q_num), 
              data = filter(d.reg, !workerid %in% exclude), 
              family = "binomial")
```

To quantify these trends, we fit a generalized logistic mixed-effects model with standardized Early Learning and Rules and Respect subscale scores, as well as interaction terms for the subscale scores by question type (i.e., control recall vs. target recall vs. target generalization) as fixed effects, and participants and questions as random effects.^[This random effects specification was the maximal convergent random effect structure.] Coefficient estimates are shown in Table \ref{tab:lmer}. Early Learning scores interacted positively with target recall and target generalization to predict correct performance, whereas Rules and Respect scores interacted positively with target recall but not target generalization, and coefficient magnitudes were relatively lower. Thus, Early Learning scores differentially predicted generalization from the target passage.^[These results held when Affection and Attachment items were included in the analysis as well. Affection and Attachment scores also moderated generalization, though not as strongly as Early Learning scores.] These results suggest that people's implicit theories about child development may organize the processing of new information in this domain.

```{r lmer, results="asis"}
# commented out, output below. 
# lmer_table <- xtable(coef(summary(lm)), caption = "Fixed-effect coefficients for logistic mixed effects model predicting task performance in Experiment 1.")

#print(lmer_table, type = "latex", comment = FALSE, include.rownames = FALSE,
#    table.placement = "t", format.args = list(big.mark = ","))
```

\begin{table}[t]
\centering
\begin{tabular}{lrrrr}
  \hline
Predictor & Estimate & Std. Error & z value & $p$ \\ 
  \hline
  Cntl recall & 1.11 & 0.37 & 2.98 & 0.00 \\ 
  Targ gen & 1.57 & 0.49 & 3.19 & 0.00 \\ 
  Targ recall & 1.28 & 0.49 & 2.59 & 0.01 \\ 
  Rules and Respect & -0.10 & 0.21 & -0.48 & 0.63 \\ 
  Early Learning & 0.27 & 0.22 & 1.22 & 0.22 \\ 
  Targ gen $\times$ R/R & -0.06 & 0.06 & -0.94 & 0.35 \\ 
  Targ recall $\times$ R/R& 0.32 & 0.06 & 5.62 & 0.00 \\ 
  Targ gen $\times$ EL & 0.62 & 0.06 & 10.86 & 0.00 \\ 
  Targ recall $\times$ EL & 0.49 & 0.05 & 8.97 & 0.00 \\ 
   \hline
\end{tabular}
\caption{Fixed-effect coefficients for linear mixed effects model predicting task performance in Experiment 1. EL = Early Learning; RR = Rules and Respect.\label{tab:lmer}} 
\end{table}

One possible explanation for these results is that participants who scored higher on the Early Learning subscale would have been more likely to respond correctly to the target generalization and recall questions even without having read the article. For example, participants with high Early Learning scores might have pre-existing knowledge that is consistent with the information presented in the target article, or might intuitively answer the questions based on their implicit theories of children's learning. To address this possibility, we conducted a second experiment in which roughly half of the participants read the articles ($n$ = 250), and the remaining half answered the recall and generalization questions without having read the articles ($n$ = 229). We found that even among participants who had not read the articles, those who scored higher on Early Learning also scored higher on target recall, $\beta$ = .49, $SE$ = .04, $z$ = 12.47, $p$<.001, and generalization, $\beta$ = .30, $SE$ = .04, $z$ = 8.00, $p$<.001. However, we also found a three-way interaction such that accuracy was higher for target generalization trials for participants who had higher Early Learning scores and were in the reading group, $\beta$ = .38, $SE$ = .07, $z$ = 5.61, $p$<.001. Thus, there is an advantage for uptake of an article about children's learning for participants who score higher on the Early Learning subscale of our questionnaire. Additionally, the fact that participants with higher Early Learning scores have higher accuracy for the target questions even without having read the article suggests that subscale scores are predictive of how parents reason about children's learning in general.

# General Discussion

Understanding the sources of parents’ behaviors and decisions with regard to their parenting is a critical step in improving children’s welfare. There is a large literature outlining the activities and environments that can make a difference in children’s development, including their language [@hart1995] and executive functioning [@barker2014]. Relevant research findings can sometimes be nuanced and unintuitive for those outside of academia, however. Thus, an important challenge is understanding the lay beliefs parents may have about parenting, and how they relate to parenting best practices as identified by developmental science. Interventions that aim to deliver new information may be more likely to succeed if they take into account the existing lay beliefs that parents hold about child development (Kumar et al., 2015). 

In the present work, we established a new scale to measure people’s attitudes about parenting and child development in three categories: Rules and Respect, Affection and Attachment, and Early Learning. These subscales are meant to capture meaningful differences in how people view child development and the relative importance of different parenting behaviors. We subjected our new scale to psychometric testing, and found acceptably high correlations among subscale items, as well as the predicted factor structure across subscales. In addition, subscale scores meaningfully predicted responses to questions about children's learning, and uptake of new information on the topic. Specifically, participants with high scores on the Early Learning subscale were more likely to generalize the message of the target article about children’s learning to new scenarios, whereas high scores on the Rules and Respect subscale did not predict generalization of the article. 

In sum, this work provides initial evidence that meaningful differences in adults’ attitudes about child development and parenting can be assessed by our new scale. This initial evidence for the reliability and validity of our parenting measure must be supplemented with further evidence in both areas across a broader range of participants. In addition, future work should target predictive validity by determining whether subscale scores differentially predict parents observable behaviors with their children, such as the quality of conversations they engage their child in, which would provide additional support for our scale.

Implicit theories are a powerful driver of human behavior. Sometimes, the interaction between interventions and their subjects' underlying beliefs can produce powerful, non-linear results [@medin2014]. Thus, given both the variability in attitudes towards parenting across cultures and the importance of improving parenting outcomes, it behooves us to understand implicit theories of parenting. The current work takes a first step in this direction. 

# Acknowledgements

This work was supported by a gift from Kinedu, Inc. Thanks to members of the Language and Cognition Lab at Stanford for helpful discussion. 

# References 



\small